# ğŸ“„ Contextual Query Engine

A Retrieval-Augmented Generation (RAG) powered chatbot that allows users to upload a PDF file and ask questions about its content. The chatbot responds only from the PDF to ensure accuracy and avoid hallucinations.  

---

## ğŸš€ Features
- Upload any PDF and query its content in natural language.
- Provides contextual answers grounded in the uploaded document.
- Simple Streamlit-based web interface for easy interaction.
- Uses ChromaDB for vector storage and retrieval.
- Powered by LangChain for pipeline orchestration and Gemini API for response generation.

---

## ğŸ› ï¸ Tech Stack
- Python
- Streamlit â€“ Web app interface
- LangChain â€“ Framework for RAG pipeline
- ChromaDB â€“ Vector database for embeddings
- Gemini API â€“ Language model for generating responses

---

## âš™ï¸ How It Works
1. PDF Upload â€“ User uploads a PDF file.  
2. Text Chunking â€“ The PDF is split into smaller text chunks.  
3. Vectorization â€“ Each chunk is converted into embeddings.  
4. Storage â€“ Embeddings are stored in **ChromaDB**.  
5. Query Handling â€“ User query is converted into a vector.  
6. Retrieval â€“ Relevant chunks are fetched from the database.  
7. Response Generation â€“ Retrieved chunks + query are passed to Gemini API, which generates an accurate answer.  

---

## ğŸ“‚ Project Structure
rag-pdf-chatbot/
â”‚â”€â”€ app.py # Main Streamlit app
â”‚â”€â”€ requirements.txt # Dependencies
â”‚â”€â”€ utils.py # Helper functions (chunking, embeddings, etc.)
â”‚â”€â”€ README.md # Project documentation

---

## â–¶ï¸ Usage

1. Clone the repository:
   ```bash
   git clone https://github.com/shahu285/contextualqengine.git
   cd contextualqengine
   
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   
3. Run the Streamlit app:
   ```bash 
   streamlit run app.py
   
4. Upload a PDF and start chatting with it!

